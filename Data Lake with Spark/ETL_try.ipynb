{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, monotonically_increasing_id\n",
    "from pyspark.sql import SQLContext\n",
    "#from pyspark.sql.types import \n",
    "from pyspark.sql.dataframe import *\n",
    "from datetime import datetime\n",
    "#from pyspark.sql.functions import timestamp\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS CREDS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS CREDS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     spark = create_spark_session()\n",
    "#     input_data = \"s3a://udacity-dend/\"\n",
    "#     output_data = \"s3a://data-lake-omkar/\"\n",
    "    \n",
    "#     process_song_data(spark, input_data, output_data)    \n",
    "#     process_log_data(spark, input_data, output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "spark = create_spark_session()\n",
    "\n",
    "input_data = \"s3a://udacity-dend/\"\n",
    "\n",
    "#song_data = os.path.join(input_data,\"song_data/A/*/*/*.json\")\n",
    "\n",
    "df = spark.read.format(\"json\").load(\"s3a://udacity-dend/song_data/A/A/A/TRAAAAK128F9318786.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: string (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+------------------+----+--------+\n",
      "|           song_id| title|         artist_id|year|duration|\n",
      "+------------------+------+------------------+----+--------+\n",
      "|SOBLFFE12AF72AA5BA|Scream|ARJNIUY12298900C91|2009|213.9424|\n",
      "+------------------+------+------------------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_songs=df.select(\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\")\n",
    "df_songs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output=\"s3a://udacity-omkar\"\n",
    "\n",
    "\n",
    "parquetfile=df_songs.write.parquet(\"songs1.parquet\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "|           song_id|duration|\n",
      "+------------------+--------+\n",
      "|SOBLFFE12AF72AA5BA|213.9424|\n",
      "+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquetfilesongs=spark.read.parquet(\"songs1.parquet\")\n",
    "\n",
    "parquetfile.createOrReplaceTempView(\"parquetfile\")\n",
    "\n",
    "artist=spark.sql(\"select song_id,duration from parquetfile\")\n",
    "\n",
    "artist.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "parquetfilesongs=spark.read.parquet(\"songs1.parquet\")\n",
    "parquetfilesongs.write.partitionBy(\"year\",\"artist_id\").parquet(\"s3a://udacity-omkar1/parquet\",\"overwrite\")\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_artist=df.select(\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\")\n",
    "\n",
    "df_artist.write.parquet(\"s3a://udacity-omkar1/artists\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data=\"s3a://udacity-dend/log_data/2018/11/*\"\n",
    "\n",
    "dflog=spark.read.format(\"json\").load(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dflog=dflog.filter(\"Page=='NextSong'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dflog.select(\"Page\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dflog.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users=dflog.select(\"userId\",\"firstName\",\"lastName\",\"gender\")\n",
    "\n",
    "users.write.parquet(\"s3a://udacity-omkar1/users\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#dflog.select(\"ts\").show()\n",
    "dftime=dflog.select(\"ts\")\n",
    "\n",
    "timefunc=udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "datefunc=udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d'))\n",
    "\n",
    "dfts=dftime.withColumn(\"ts\",timefunc(\"ts\"))\n",
    "dftime.withColumn(\"ts\",datefunc(\"ts\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "timedf=dfts.select(\n",
    "            date_format('ts','h:m:s a ').alias(\"start_time\"),\n",
    "            hour('ts').alias('hour'),\n",
    "            dayofmonth('ts').alias('day'),\n",
    "            weekofyear('ts').alias('week'),\n",
    "            month('ts').alias('month'),\n",
    "            year('ts').alias('year'),\n",
    "            date_format('ts','E').alias('weekday'))\n",
    "\n",
    "timedf.write.partitionBy(\"year\",\"month\").parquet(\"s3a://udacity-omkar1/time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "input_data = \"s3a://udacity-dend/song_data/A/A/A/*.json\"\n",
    "df=spark.read.format(\"json\").load(input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "timefunc1=udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%H:%M:%S'))\n",
    "\n",
    "songplays=df.join(dflog,(df.title==dflog.song) & (dflog.artist==df.artist_name) ).select( timefunc1('ts').alias('start_time'),\"userId\",\"level\",\"song_id\",\"artist_id\",\"sessionId\",\"location\",\"userAgent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#songplays=df.join(dflog,(df.title==dflog.song) ).select('ts',\"userId\",\"level\",\"song_id\",\"artist_id\",\"sessionId\",\"location\",\"userAgent\").show()\n",
    "\n",
    "songplays=songplays.withColumn(\"songplay_id\",monotonically_increasing_id())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- songplay_id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
